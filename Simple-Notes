How to set up Kubernetes Cluster?

Setup AWSCLI and IAM Role
Create an IAM role for eks
Install and configure eksctl
Create EKS cluster
Install and configure kubectl
Deploy application

-----------------------------------------------------------

How to update particular Node in Kubernetes cluster?

Determine the node group
Update the Launch Template
Update the node group
Cordon the Node
Drain the Node
Terminate the Node

----------------------------------------------------------

What is Kubernetes and how Kubernetes works?

Containers
Cluster
Master Node
Worker Node
Kubernetes APIs
Controllers
Scheduler
Networking
Storage
Logging and Monitoring

------------------------------------------------------------

How to deploy an application in Kubernetes?

Containerize your application
Create Kubernetes manifests
Deploy your application
Monitor your application
Scale your application
Update your application
Handle storage
Ensure Networking
Set up Logging and Monitoring
Implement security measures

-----------------------------------------------------------

How to deploy application using k8s and Argo CD?

Argo CD is a continuous delivery tool for Kubernetes that follows the GitOps methodology, meaning your Kubernetes manifests are stored in a Git repository.

Prerequisites for deploying application using Kubernetes and Argo CD
1.Kubernetes Cluster
2.Argo CD installed
3.Git Repository

Install Argo CD
Access Argo CD UI
Get Argo CD Initial Admin Password
Log in to Argo CD
Create a Git Repository with Kubernetes Manifests
Create an Argo CD Application

In the Argo CD UI:

Click on New App.

Enter the Application Name:
Project:
Sync Policy: 
Repository URL:
Access Argo CD UI
Get Argo CD Initial Admin Password
Revision: 
Path:
Cluster URL:
Namespace:

Sync the Application
Monitor the Deployment

-------------------------------------------------------------

Types of Services In Kubernetes?

1.NodePort
2.LoadBalncer
3.ClusterIp
4.External name

--------------------------------------------------------------

Kubernetes Architecture?
1.Master Node or Control Plane
2.Worker Node or Data Node

1.Master Node or Control Plane:

1.Kube API server
2.Kube Scheduler
3.Controller Manager
4.Etcd

2.Worker Node or Data Node:

1.Kube Proxy
2.Kubelet
3.Conatiner runtime
a.Low level container run times(runc, continer-d)
b.High level container run times(cri-o docker)
c.sandbox and virtualized containers

-------------------------------------------------------------

How does kubernetes achive high availability?

Replicaset and Deployments
LoadBalancing
Pod distruption budget
ReplicaSet
Cluster AutoScaler

-------------------------------------------------------------

Your application experiences traffic spikes.How would you handle aitomatic scaling in kubernetes?

Horizontal Pod Autoscaler(HPA)
Cluster Autoscaler:
Automatically scales the number of nodes in the cluster based on the demand

-------------------------------------------------------------

How do you optimise the performance of a kubernetes application?

Resource requests and limits:
Set appropriate resource requsets and limits for pods.

Horizontal Pod Autoscaler:
Horizontal Pod Autoscaler automatically scales the number of pods in a deployment,replicaset or stateful set based on the observed cpu utilization or custom metrics.

Efficient Image Building:
Create minimal container image to reduce startup time.

Network optimization:
Use network policies and service types effectively.


-------------------------------------------------------------

What will you do if the disk is full?

Identify Large Files and Directories
Remove Unnecessary Files
Clear System logs
Clean Package Cache
Resize Partitions
Move Large Files or Directories
Compress Large Files or Directories using zip or tar

------------------------------------------------------------

How to secure, store credential in Jenkins?

Credential Plugin
Environment Variables
Hashicorp Vault
Third Party secrets management tools

------------------------------------------------------------

How to back Jenkins?

Thin Backup

Configuration folder
Plugins
Jobs
User Content
Database

-----------------------------------------------------------

How to Move Jenkins from one server to another server?

Backup Jenkins Home Directory
Install Jenkins on target server
Transfer backed up Jenkins Home Directory
Start Jenkins on new server
Verify configuration and functionalities
Monitor and Troubleshoot

------------------------------------------------------------

How to upgrade Jenkins?

Backup Jenkins data
Stop the Jenkins Service
Choose Upgrade Method
Package manager
Manual Upgrade
Upgrade Jenkins using yum
Start the Jenkins
Verify Upgrade
Update Plugins
Monitor and Trouble Shoot

-------------------------------------------------------------

How do you Monitor Jenkins and its jobs?

Jenkins Dashboard
Build history
Build Trend Analysis
Job notifications
Monitoring Plugins
Job queues

--------------------------------------------------------------

Features of Jenkins

Extensibilty and Pugins
Distributed Build
MasterSlave Architecture
Pipeline as a code
Integration with various tools
Job Notification
Monitoring
Security and Features
Support for containerization
Support Parallel stages or Parallel pipelines
Job queues

--------------------------------------------------------------

How Jenkins pipeline Fail?

Syntax error in Jenkins file
Invalid or Missing Credentials
Environment Issues
Incorrect Branch or Repository Configuration
Incorrect usage of Plugins
Resource limits
Network Issues
Duplicate Stage Names
If the agent or node is offline

----------------------------------------------------------------
Types of pipelines you're handling in your project:

1.CI/CD Pipelines

a.Continuous Integration (CI) Pipelines
b.Continuous Deployment (CD) Pipelines

2.Infrastructure as Code (IaC) Pipelines
3.Release Pipelines
4.Security and Compliance Pipelines
5.Data Pipelines
6.Monitoring and Alerting Pipelines
7.Migration and Backup Pipelines

60 + Pipelines

---------------------------------------------------------------

How to design well architecture in AWS?

Reliability
Performance Efficiency
Security
Cost Optimization
Operational Excellence

-----------------------------------------------------------------

How to design highly available architecture in AWS?

Use Multiple Availability zones
Load Balancing
Autoscaling
Database Replication
Distributed Data Storage
Fault tolerant Architectures
Monitoring and Alerting
Disaster Recovery

------------------------------------------------------------------

Explain AWS Architecture in your Project?

Core Components:

VPC(Virtual Private Cloud)
EC2(Elastic Compute Cloud)
Relational Database
S3
EKS

Networking and Security:

Security Group
NACL
IAM
Route 53

Monitoring and Logging:

CloudWatch
CloudTrail

CI/CD and Automation:
Jenkins

Other Services:

Lambda
SQS
SNS
SES

Security and Compliance:

KMS keys
AWS WAF and WAF Shield 

--------------------------------------------------------------

EC2 Instance Families:

General Purpose Instances
Compute Optimized
Memory Optimized
Storage Optimized Instances
Accelerated Computing

-----------------------------------------------------------

EC2 Instance Purchase Options:

On-demand Instances
Reserved Instances
Scheduled Instances
Dedicated Host
Spot Instances
Savings Plan

-----------------------------------------------------------

EBS Volume Types:

1.SSD Volumes
2.HDD Volumes
3.Magnetic Storage


1.SSD Volumes: Designed for Transactional Workloads
a.General Purpose HDD Volumes(gp3,gp2)
b.Provisioned iops HDD Volume(io2 block express,i02,i01)

2.HDD Volumes: Designed for Streaming Workloads
a.Throughput optimized HDD volumes
b.Cold HDD volumes

3.Magnetic Storage

------------------------------------------------------------

Load Balancer Types:

1.Classic LoadBalancer
2.Network LoadBalancer
3.Gateway LoadBalancer
4.Network LoadBalancer

-------------------------------------------------------------

AutoScaling Policies:

1.Target Tracking
2.Simple Scaling
3.Step Scaling
4.Scheduled Scaling
5.Predictive Scaling

--------------------------------------------------------------

S3 Storage Classes

1.Standard
2.Reduced Redundancy
3.Standard IA(Infrequently Accessed)
4.Intellegent Tiering
5.One Zone IA
6.Glacier
a.Glacier Instant Retrieval
b.Glacier Flexible Retrieval
c.Glacier Deep Archive

-------------------------------------------------------------
AWS Lambda:

AWS lambda is a serverless compute service provided by AWS. It allows you to run code without provisioning or managing servers.

Features of AWS Lambda:

1.Event driven execution
2.Automatic Scaling
3.Cost Efficiency
4.Managed Service
5.Support Multiple Languages

-------------------------------------------------------------
AWS Fargate:

AWS Fargate is a serverless compute engine provided by AWS. It allows you to run code without prvisioning or managing servers.

Features of AWS Fargate:

1.Compatible with Amazon ECS or Amazon EKS
2.Serverless and pay-as-you-go
3.Supports multiple CPU architectures and Operating Systems

-------------------------------------------------------------

How to Update Terraform Version:

1.Download the new version
2.Extract the Package
3.Update Environment Variables
4.Verify Installation

-------------------------------------------------------------

Terraform Modules: 

In terraform module is a folder that conatians reusable terraform code such as locals, resources, data sources.

1.Root Module
2.Child Modules
3.Published Modules
4.Using Modules
5.Developing Modules

Uses cases of Terraform Module:

1.Infrastructure Templating
2.Reusable Infrastructure Components
3.Application Deployment
4.Compliance and Security
5.Disaster Recovery and Backup
6.Cloud Provider Abstraction

--------------------------------------------------------------

Features of Terraform:

1.Multi Cloud Deployment
2.Infrastructure Orchestration
3.Immutable Infrastructure
4.Infrastructure as a code
5.CI/CD pipeline
6.Environment Provisioning
7.Resource Scaling and Management

--------------------------------------------------------------

The Arguments Available with in a Life Cycle Block are:

1.Create Before Destroy
2.Prevent Destroy
3.Ingnore Changes
4.Replace trrigered by

---------------------------------------------------------------

Resources you've created using Terraform:

1.Networking Components:

1.VPCs (Virtual Private Clouds)
2.Subnets
3.Route Tables and Associations
4.Security Groups and Network ACLs
5.Internet Gateway
6.Tarnsit Gateway

2.Compute Resources:

1.EC2 Instances
2.Auto Scaling Groups:
3.Lambda Functions

3.Storage Resources:

1.S3 Buckets
2.EBS Volumes

4.Database Services:

1.RDS Instances
2.DynamoDB Tables

5.IAM and Security:

1.IAM Roles, Policies, and Users

6.Load Balancing and Distribution:

1.Elastic Load Balancers
2.Route 53

------------------------------------------------------------

Summary of the Deployment Stages Order

1. Development: For Initial coding and unit testing.
2. Testing: Automated and integration testing to catch functional issues.
3. UAT (User Acceptance Testing): Validation by end-users or business stakeholders.
4. Staging: Pre-production environment for final testing under conditions similar to production.
5. Production: Live environment where the application is used by real users.

--------------------------------------------------------------

Why do Docker Containers fail?
1. Container Startup Issues

Misconfigured Entrypoint or Command: 

If the entrypoint or command in the Dockerfile  is incorrect, 
the container may exit immediately.

If the docker run command is incorrect, the container may exit immediately.

Missing Dependencies:

2. Resource Constraints

Out of Memory (OOM): If the container exceeds the available memory, the system may kill it.

CPU Limits: Containers restricted by CPU limits may fail under high load.

3. Docker Daemon Issues

Corrupted Docker Installation: If Docker itself has issues, 
containers may not run properly.

Insufficient Disk Space: If the system runs out of disk space, 
Docker containers may fail to start

4. Incorrect Docker Image

Wrong Image Tag: Pulling the wrong image version can
lead to compatibility issues.
Corrupted Image: If the Docker image is corrupted, 
the container may not start.

----------------------------------------------------------------

We have developments branch for dev activities, test branch for test activities, release branch for doing particular release and feature branches for adding new features to the system.


We use one VPC for one environment. Development has a separate one. Testing has a separate one. UAT has a separate one. stage has a separate one Production has a separate one. We are segregating them with TerraForm workspaces.

---------------------------------------------------------------

Infrastructure and Transportation(Highways England)

---------------------------------------------------------------
Path to the interpreter that should execute the script.
------------------------------------------------------------------
Environmental Variable in Jenkins are key-value pairs used to pass 
information to jobs,pipelines,scripts during the build process.
------------------------------------------------------------------
A hypervisor is software that creates and manages virtual 
machines by allocating hardware resources to them.
------------------------------------------------------------------
Control Node is the server where the ansible is installed.
------------------------------------------------------------------
Manging Node is the server that is configured using ansible.
------------------------------------------------------------------
Virtualization is the process of creating virtual versions of 
computing resources, such as servers, storage, or networks.
------------------------------------------------------------------
-o StrictHostKeyChecking=no 
prevents SSH from prompting and automatically accepts the host key.
------------------------------------------------------------------
-y: Automatically answers "yes" to any prompts during the installation.
------------------------------------------------------------------
tar → A Linux utility used for compressing and extracting archive files.
x → Extracts the files from the archive.
------------------------------------------------------------------
sudo → Runs the command with superuser (root) privileges.
------------------------------------------------------------------
-R → Recursively applies changes to all files and subdirectories.
------------------------------------------------------------------

maxSurge: Represents the maximum number or percentage of Pods that can be 
created above the desired number of replicas during an update. Here, it is set to 25%.

maxUnavailable: Represents the maximum number or percentage of Pods that can be 
unavailable (not running) during an update. Here, it is set to 25%.

--------------------------------------------------------------------------

Copying the nginx.conf file from the current machine to the 
/etc/nginx/nginx.conf directory on the target machine ensures 
that the Nginx server on the target machine is configured according
to the specifications defined in the nginx.conf file.

--------------------------------------------------------------------------

resources: Defines the resource requirements and limits for the container.

requests: Specifies the minimum amount of resources the container needs.

limits: Sets upper limits on the resources the container can consume.

--------------------------------------------------------------------------

ports: Specifies the ports to open on the Service.

port: 80: Defines that the Service should listen on port 80.

targetPort: 80: Specifies that the traffic should be forwarded to Pods on port 80.

nodePort: 30000: Opens a specific port on all nodes in the cluster,
allowing external traffic to reach the Service.

--------------------------------------------------------------------------

Pipeline Block: Encloses the entire Jenkins Pipeline script.
agent any: Execute pipeline on any any available agent in Jenkins environment.
stages: Defines the stages of the Pipeline.
stage('Install Docker'): Defines a stage named "Install Docker".
steps: Contains the steps to be executed within this stage.
script: Allows running shell scripts within the Pipeline. 

--------------------------------------------------------------------------

Core API Group (v1)
Extended API Group (apps/v1)

v1: Used for core, stable, and essential resources like Pods, Services, ConfigMaps, etc., 
which are part of Kubernetes' fundamental operations.

apps/v1: Used for more complex, application-related resources like Deployments, 
StatefulSets, and DaemonSets, which are managed separately to allow for greater flexibility and evolution.

--------------------------------------------------------------------------

Recursively

-r: Primarily used in commands like rm and cp for recursive operations, 
and it usually has the same meaning as -R.
-R: Also used for recursive operations but is more commonly used in commands
like chmod and chown for recursively changing permissions or ownership.

--------------------------------------------------------------------------

In Aws management console --> Click on Instance --> Actions 
--> Instance Settings --> Change Termination Protection -- Enable

In Aws management console --> Click on Instance --> Actions 
--> Instance Settings --> Change Instance Type --> Select Instance Type and then save

In Aws management console --> Click on Instance --> Actions 
--> Monitor and troubleshoot --> Get Instance ScreenShot

In Aws management console --> Click on Instance --> Actions 
--> Image and Templates --> Create Image

In Aws management console --> Click on Instance --> Actions --> Security --> 
Modify IAM Role --> Choose IAM Role --> Update IAM Role

In Aws management console --> Click on Instance --> Connect --> 
EC2 Instance Connect --> Connect

In Aws management console --> Click on VPC --> Actions --> Edit CIDRs -->
Add new IPv4 CIDRs --> and then click on save

--------------------------------------------------------------------------

While launching ec2 Instance --> Adavnced details --> Termination Protection 
--> Enable

While launching ec2 Instance --> Click on Storage --> EBS Volume 
-->Delete on Termination --> By Default Yes --> Make it has No

While launching ec2 Instance --> Advanced network configuration --> Under Primary IP
--> Enter the Private IP ---> then launch Instance

For Internet-facing load balancers:
Open the Load Balancers section --> Select your Load Balancer -->
View Load Balancer details --> Description tab

For Internal load balancers: 
Check the "Network interfaces" section in the "Description" tab. 
You'll find the private IP addresses

Click On Loadbalancer --> Attributes --> Edit --> Load Balancer Attributes -->
Termination Protection--> Enable --> Save Changes

-------------------------------------------------------------------------------

Elastic Beanstalk is a cloud service by AWS that simplifies the
deployment and management of applications. It automatically handles 
the infrastructure,scaling, and monitoring.

1. Infrastructure as a Service (IaaS)

Example:
Amazon Web Services (AWS) EC2 
Microsoft Azure Virtual Machines
Google Compute Engine (GCE)

2. Platform as a Service (PaaS)

Example:
Google App Engine 
Microsoft Azure App Services

3. Software as a Service (SaaS)

Google Workspace
Microsoft 365

Node Selcetor/Node Affinity
Required During Scheduling Ignore During Execution
Preffered During Scheduling Ignore During Execution

Readiness/liveness/Start Up probe
----------------------------------------------------------------------------

Shebang line:

 Path to the interpreter that should execute the script.

-y: Automatically answers "yes" to any prompts during the installation.
-f: Forces the pruning action without prompting for confirmation.
The -i option in the ssh command stands for identity file.

----------------------------------------------------------------------------
docker --version
Docker version 25.0.8

jenkins --version
2.492.2
java-17

git --version
git version 2.47.1


mvn --version
Apache Maven 3.8.4
java-17

-------------------------------------------------------------------
sudo → Runs the command with superuser (root) privileges.
tar → A Linux utility used for compressing and extracting archive files.
x → Extracts the files from the archive.
f → Specifies the filename of the archive to extract.
apache-tomcat-9.0.102.tar.gz → The archive file that contains the Tomcat files.

---------------------------------------------------------------------

sudo → Runs the command with superuser (root) privileges.
chown → Changes ownership of files/directories.
-R → Recursively applies changes to all files and subdirectories.
ec2-user:ec2-user → Sets both owner and group to ec2-user.
tomcat9/ → The target directory (including / ensures it's a directory).

---------------------------------------------------------------------

PuTTY Key Generator --> Load your pem file --> Save Private Key with.ppk 
--> Download putty private key.

Click on PuTTY 
Session:
Host Name or IP Adress:ec2-instance Public IP
Port: 22
Connection type: SSH
Then Connection --> SSH --> Auth --> Credentials --> Private key file for Authentication Browse
Select the Key --> open --> Login as: ec2-user

-----------------------------------------------------------------------

MobaXterm 

Click on Session --> SSH --> Remote host: Public IP --> Specify username: ec2-user --> port: 22

Advanced SSH settings --> Clock on use Private key --> Slect file --> open --> Click on OK

------------------------------------------------------------------------

While Creating VPC what are all the resources implicitly Created?

Default Route Table, Default NACL, Default Security Group, Implicit Router

------------------------------------------------------------------------

Helm is a package manager for Kubernetes,It simplifies the 
deployment and management of applications in Kubernetes clusters 
by using Helm charts.

------------------------------------------------------------------
Instance Warm Pool

Instances take a long time for bootstrapping, 
to avoid such long waiting times we can maintain a warm pool.

------------------------------------------------------------------
VPC Endpoints 

VPC endpoints enable private connections between your Amazon VPC and supported AWS
services without using the public internet, enhancing security and reducing latency.

------------------------------------------------------------------

      -o StrictHostKeyChecking=no ****
   prevents SSH from prompting and automatically accepts the host key

------------------------------------------------------------------

Classless Inter-Domain Routing(CIDR) is an IP adress allocation method.

------------------------------------------------------------------

VPC Components:
VPC, Subnets, Route Tables, Internet Gateway, NAT Gateway, Security Groups,
NACL, VPC Peering, Endpoints, Elastic IP. 

------------------------------------------------------------------

./ --- Current Directory

------------------------------------------------------------------

   -o StrictHostKeyChecking=no ****
   prevents SSH from prompting and automatically accepts the host key.

------------------------------------------------------------------

1.How do you troubleshoot an ec2 instance that is unreachable?

1.Check instance state in AWS management console if it is stopped or running
2.Check instance checks and systemchecks in EC2 console
3.Verify Security Groups and NACLs inbound rules
4.Check the Route Table for proper internet routng
5.Ensure the EC2 instance has a public and private IP

------------------------------------------------------------------

2.How do you secure a VPC?

1.Use Security Groups and NACLs
2.Enable VPC Flow Logs for monitoring
3.Use Private Subnets for sensitive purpose
4.Add a NAT Gateway for secure internet access

------------------------------------------------------------------

3.How do you enforce security best practices in AWS?


1.Use IAM least previlege access
2.Enable MFA for IAM users and root account
3.Use AWS WAF and AWS Shiels for network security
4.Use S3 encryption,bucket policies and S3 versioning
5.Use KMS keys for encryption

------------------------------------------------------------------

4.What is the difference between AWS WAF and AWS Shield?

AWS WAF:Protects Against Dos Attacks, DDos Attacks at Layer 7, 
Cross-Site scripting, SQL Injection, IP-Based Attacks

AWS Shiled: Protects Aginst DDos attcks at Layers 3 & 4 , EC2,
ELB, CloudFront, Route 53, AWS Global Accelerator

------------------------------------------------------------------

5.How do you secure an S3 bucket from unauthorized acess?

1.Use Bucket Policies
2.IAM Roles
3.Block Pubic Access
4.Enable S3 Server-Side Encryption

------------------------------------------------------------------

6.How do you monitor an RDS database in AWS?

1.Use CloudWatch metrics(CPU, Memory, Connections) 
2.Enable Enhanced Monitoring for OS-level insights
3.Enable RDS logging(Slow Query Log, Error Log)  

------------------------------------------------------------------

7.How do you monitor AWS resources in real time?

1.Use AWS CloudWatch to monitor logs and metrics
2.AWS X-ray for tracing
3.AWS CloudTrail to track user activity and API usage

------------------------------------------------------------------

8.How do you scale an RDS database?

1.Use Multiple-AZ deployments for high availability
2.Use Read Replicas for read-heavy workloads

------------------------------------------------------------------

9.How does AWS handles data encryption at rest and in transit?

At rest:Use KMS keys, S3 Server-Side Encrytion, EBS Encryption,
RDS Encryption

In transit:Use TLS encrytion for data trasfer

------------------------------------------------------------------

10.How do you optimize costs in AWS?

1.Use Reserved Instances or Savings Plans
2.Use S3 Intelliigent-Tiering
3.Use Auto Scaling
4.Use Spot Instances
5.Use AWS services like AWS Cost Explorer, AWS Budgets and AWS
 Trusted Advisror to monitor and optimize costs

------------------------------------------------------------------
11.What is the difference between ECS and EKS?

ECS(Elastic Container Service) is AWS managed service and supports Forgate
EKS(Elastic Kubernetes Service) runs kubernetes workloads with more flexibility

------------------------------------------------------------------

12.How do you migrate an on-premises database to AWS with mimimal downtime?

Use AWS Data Migration Service(DMS) with CDC(Change Data Capture) 
to sync changes continuously 

------------------------------------------------------------------

13.How do you create a serverless API in AWS?

Use API Gateway + AWS Lamda + DynamoDB

------------------------------------------------------------------

14.How do you automate EC2 babckups?

By using AMIs and Snapshots
By using Amazon Data Lifecycle Manager
By using AWS Backup

------------------------------------------------------------------

15.How do you implement CI/CD in AWS?

Use CodePipeline with CodeCommit(Git repo), Code Build(build automation),
CodeDeploy(Deployment).Optinally use EKS or ECS 

------------------------------------------------------------------

16.What are some ways to optimize Lamda Costs?

1.Choose the right memory size
2.Use Provisioned Concurrency only when necessary
3.compress and minify code to resduce the execution time
4.Monitor with CloudWatch to identify inefficiences

------------------------------------------------------------------

17.How do you troubleshoot a failed Lamda function exexution?

Check Amazon CloudWatch Logs, AWS X-Ray(if enabled for tracing),
and the DLQ(Dead Letter Queue) if configured.

------------------------------------------------------------------

18.How do you improve Lamda cold start performance?


1.Use Provisioned concurrency
2.Keep function size small and dependencies minimal
3.Choose a smaller runtime
4.Keep Lambda warm using scheduled invocations

------------------------------------------------------------------

"I’m looking for new challenges and opportunities to 
grow my skills in DevOps and AWS.




















































































