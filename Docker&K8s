FROM        -- Specifies the base image for the docker image
WORKDIR     -- Sets the Working Directory inside the docker image
RUN         -- RUN is the docker build time instruction
CMD         -- CMD is the docker run time instruction
COPY        -- COPY copies files and folders from host machine to image
ADD         -- ADD copies file and folders from host machine to image
               ADD have an extra capability, It Downloads the file from URL
               And also it auto extract the compressed file
EXPOSE      -- Exposes port to the host machine
CMD         -- CMD can be Overridden at run time
ENTRYPOINT  -- ENTRYPOINT cannot be overridden at run, it is getting appended
               CMD and ENTRYPOINT cab be used together
ARG         -- ARG is the docker build time Argument
ENV         -- ENV is the docker run time Argument
LABEL       -- To add Metadata
USER        -- To run application using specific user
HEALTHCHECKS-- To check the health of the application
. Indicates -- Current Directory as build context
-d          -- Detached Mode(in the background)
-it         -- Interactive Terminal(in the foreground)
-itd        -- Interactive Terminal Detached Mode
 

-----------------------------------------------------------------------------------------

FROM nginx:latest
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]

FROM openjdk:11-jre-slim
WORKDIR /app
COPY app.jar .
EXPSOE 8080
CMD ["java", "-jar", "app.jar"]

FROM alpine:3.18.2
RUN apk add python3
RUN apk add py3-pip
WORKDIR /app
COPY requirements.txt .
RUN pip3 install -r requirements.txt
COPY app.py .
EXPOSE 80
CMD ["python3","app.py"]


FROM node:18
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY server.js .
EXPOSE 8080
CMD ["node","server.js"]


FROM alpine:3.18.2
RUN apk add openjdk11
WORKDIR /tomcat
ADD https://downloads.apache.org/tomcat/tomcat-9/v9.0.102/bin/apache-tomcat-9.0.102.tar.gz .
RUN tar xf apache-tomcat-9.0.102.tar.gz && rm apache-tomcat-9.0.102.tar.gz
EXPOSE 8080
CMD [/tomcat/apache-tomcat-9.0.102/bin/catalina.sh, "run"]

Extract the contents of the apache-tomcat-9.0.91.tar.gz archive.
Remove the archive file after extraction to save space in the Docker image.
----------------------------------------------------------------------------------------------

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deployment
  labels:
    app: my-app
spec:
  replicas: 3  # Desired number of pods
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-container
        image: my-image
        ports:
        - containerPort: 80
---
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: my-deployment-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-deployment
  minReplicas: 2  # Minimum number of pods
  maxReplicas: 10  # Maximum number of pods
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50  # Target average CPU utilization
-----------------------------------------------------------------------

docker ps 
docker ps -a
docker ps -aq
docker rm container_id
docker rm -f container_id
docker rm -f $(docker ps -aq)    (removes all the containers including running and exited)   (-aq --- all conatiner_ids)
docker ps --filter="status=exited" -q                                                       (-q --- container_ids)
docker ps -f="status=exited" -q
docker ps -f "status=exited" -q
docker rm -f $(docker ps --filter="status=exited" -q)
docker rm -f $(docker ps --filter="status=running" -q)

docker images
docker rmi image_id
docker rmi -f image_id
docker rmi -f $(docker images -q) (removes all the images including dangling and non-dangling)
docker images --filter="dangling=true" -q
docker images -f="dangling=true" -q
docker images -f "dangling=true" -q
docker rmi -f $(docker images --filter="dangling=true" -q)
docker rmi -f $(docker images --filter="dangling=false" -q)

docker logs container_id
docker stats
docker exec -it container_id bash
docker inspect container_id
docker-compose up -d
docker-compose ps
docker network create --driver=bridge network_name
docker network list
docker network inspect network_name


docker image prune -f
docker system prune -f
docker history image_id

docker volume create jenkins
docker volume inspect jenkins
docker volume ls
docker volume rm jenkins
docker run -d -p <host_port>:<container_port> --name <container_name> -v manju:/path/inside/container   
<image_name>:<tag>
docker run -d -p 8080:8080 -p 50000:50000 -v jenkins:/var/jenkins_home --name jenkins jenkins/jenkins

docker info
docker login -u user_name
docker push user_name/<image_name>:<tag>
docker pull <image_name>
printenv
exit

/var/lib/docker/volumes  --- Docker Volumes are stored in

To copy a file or directory from the host machine to a running Docker container
docker cp <source_file_path> <container_name>:<container_file_path>

To copy a file from a running Docker container to the host machine
docker cp <container_name>:<container_file_path> <host_file_path>


docker run -itd --name=one alpine 
docker run -itd --name=two alpine 

docker run -itd --name=one --network=manju_jhc alpine
docker run -itd --name=two --network=manju_jhc alpine

docker run -it manjukempaiah/tomcat:0.0.1 

docker build -t manjukempaiah/<image_name>:<tag> .
docker build -t user_name/<image_name>:<tag> .
docker build -t <nexus_repo_url>/<image_name>:<tag> .

Reads the dockerfile to build an image.
Uses docker engine to execute each instruction in the dockerfile

docker build -t manjukempaiah/tomcat:0.0.1 . --build-arg JAVA_PKG=openjdk8


docker run -d -p <host_port>:<container_port> --name container_name <image_name>:<tag>

pulls the requested image from dockerhub if not available locally.
Create a conatiner from the image
Assisgns a unique container_id
Runs the container in the docker engine

docker run -it -e CONFIG_FILE="/app/prod.config" manjukempaiah/tomcat:0.0.1 
docker run -it --env-file ./manju.env manjukempaiah/tomcat:0.0.1

How do you limit container resources in docker?

docker run --cpus="2" --memory="512m" imagename
docker run --cpus="2" imagename
docker run --memory="512m" imagename


docker stop container_id  --- Gracefully stpos the container
docker rm container_id    --- Removes the stopped container
docker kill container_id  --- Immediately stops the container without cleanup
docker top container_id   --- To Diplay the running processes inside the container
docker stats container_id --- To Check resource usage of running container


docker run -e DB_PASSWORD=$DB_PASSWORD myapp
docker commit <container-id> recovered-image


---------------------------------------------------------------------

In Docker, ARG and ENV are both used to define variables

ARG (Build-time Argument)

ARG is the docker build time argument
Used to pass variables at build time

ENV (Environment Variable)

ENV is the docker runtime argument
Used to pass variables at run time

---------------------------------------------------------------------

Docker Engine contains the following main components:

Docker Daemon:

Docker CLI:

The command-line interface used by developers to interact with the Docker Daemon.

Docker REST API:

Allows communication between the Docker CLI and Docker Daemon.

---------------------------------------------------------------------

git init
git clone https://github.com/ManjuKempaiah/docker-repo.git
cd docker-repo
ls 

----------------------------------------------------------------------

kubectl run myapp --image=nginx --port=80
kubectl run nodeapp --image=manjukempaiah/node-web-app --port=8080
kubectl expose pods/myapp --type="NodePort" --port 8080

eksctl create cluster --name=jhc-aug-dev
eksctl create cluster --name=jhc-aug-dev --nodes=5
eksctl delete cluster --name=jhc-aug-dev 


kubectl create -f pods.yml
kubectl apply -f pods.yml
kubectl delete -f pods.yml

The -f flag in the kubectl command stands for file


kubectl logs <pod_name>
kubectl logs <pod_name> -c conatiner_name
kubectl describe pod <pod_name>
kubectl describe pod <pod_name> -c container_name
kubectl describe pod <pod_name> -n namespace | grep "Restart Count"
kubectl exec -it <pod_name> -- /bin/bash
kubectl exec -it pod_name -c container_name -- /bin/bash
kubectl get pods -o wide


To find pods that are not ready
kubectl get pods | grep "0/"

To find all pods across all namespaces that are not ready
kubectl get pods -A | grep "0/"


To find all failed pods in the current namespace,
kubectl get pods --field-selector=status.phase=Failed

To find failed pods across all namespaces, add the -A flag:
kubectl get pods -A --field-selector=status.phase=Failed


kubectl describe deployment deployment_name -n namespace


kubectl rollout status deployment deployment_name -n namespace
kubectl rollout undo deployment deployment_name -n namespace
kubectl rollout undo deployment deployment_name -n namespace --to-revision=n
kubectl rollout restart deployment deployment_name -n namespace
kubectl rollout history deployment deployment_name -n namespace
kubectl describe deployment deployment_name -n namespace


kubectl scale deployment <deployment_name> -n <namespace> --replicas=3
Kubectl scale rs nginx -n namespace --replicas=n

kubectl set image deployment <deployment-name> <container-name>=<image-name>:<tag>
kubectl top pod <pod-name>

kubectl get pods --show-labels -n <namespace>
kubectl get endpoints <service-name> -n <namespace>
sudo systemctl stop kubelet
sudo systemctl start kubelet


kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
kubectl edit svc/argocd-server -n argocd
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

sudo vi deployment.yml
esc Shit+: wq
10 dd to delete lines in the file
cat deployment.yml To show content in the file
----------------------------------------------------------------------------------------------

Nginx playbook

- hosts: 172.31.41.58
  become: True
  tasks:
    - name: configure nginx rpm
      yum: name=http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm
    - name: install nginx
      yum:
        name: nginx
        state: present
    - name: copy nginx config file
      copy:
        src: nginx.conf
        dest: /etc/nginx/nginx.conf
      notify:
          - restart nginx
    - name: start and enable
      service:
        name: nginx
        state: started
        enabled: True
  handlers:
    - name: restart nginx
      service :
        name: nginx
        state: restarted

Copying the nginx.conf file from the current machine to the /etc/nginx/nginx.conf directory on the target machine ensures that the Nginx server on the target machine is configured according to the specifications defined in the nginx.conf file.

This triggers the restart nginx handler whenever the file is changed.
Handlers run only if the task makes changes (e.g., if nginx.conf is modified).

-------------------------------------------------------------------------------------------------------------------

Apache playbook

- hosts: 172.31.36.99
  become: True
  tasks:
    - name: install apache
      yum:
        name: httpd
        state: present
    - name : put sample html file on apache
      copy:
        src: index.html
        dest: /var/www/html
    - name: start and enable apache
      service:
        name: httpd
        state: started
        enabled: True     
-----------------------------------------------------------------------------------------------------------------
Ansible tags

- hosts: web
  become: True
  tasks:
    - name: Install apache
      yum:
        name: httpd
        state: present
      tags:
          - install
    - name: put sample html file on apache
      copy:
        src: index.html
        dest: /var/www/html/
      tags:
          - deploy
    - name: start and enable apache
      service:
        name: httpd
        state: started
        enabled: True
      tags:
          - start

-------------------------------------------------------------------------------------------------------------------

Can you please write ansible playbook conditionally install a package,if it is linux how to install package,if it is ubuntu how to install a package.

- hosts: 172.31.36.99
  become: True
  tasks:
    - name: install apache on linux
      yum:
        name: httpd
        state: present
      when: ansible_facts['os_family'] == "RedHat"
    - name: install apache on ubuntu
      apt:
        name: apache2
        state: present
      when: ansible_facts['os_family'] == "Debian"

-------------------------------------------------------------------------------------------------------------------

Docker install

- hosts: localhost
  become: True
  tasks:
    - name: install docker
      yum:
        name: docker
        state: present
    - name: Grant ec2-user permissions on docker
      command:
        cmd: "usermod -a -G docker ec2-user"
    - name: start docker
      service:
        name: docker
        state: started

-------------------------------------------------------------------------------------------------------------------

node.js install 
  
- name: Install Node.js
  hosts: your_target_hosts
  become: yes
  tasks:
    - name: Install Node.js
      apt:
        name: nodejs
        state: present
      when: ansible_distribution == 'Ubuntu'
    - name: Install Node.js on CentOS
      yum:
        name: nodejs
        state: present
      when: ansible_distribution == 'CentOS'
    - name: Install Node.js on Amazon Linux
      yum:
        name: nodejs
        state: present
      when: ansible_distribution == 'Amazon'

-------------------------------------------------------------------------------------------------------------------

Copy file from EC2 to target machine

- name: Copy file from EC2 to target machine
  hosts: target_machine
  become: yes
  tasks:
    - name: Copy file from EC2 to target machine
      copy:
        src: /path/to/source/file/on/ec2
        dest: /path/to/destination/folder/on/target_machine


-------------------------------------------------------------------------------------------------------------------

pods.yml

apiVersion: v1
kind: Pod
metadata:
  name: myapp
  labels:
    name: myapp
spec:
  containers:
    - name: myapp
      image: nginx
      resources:
        requests:
          memory: "128Mi"
          cpu: "250m"
        limits:
          memory: "256Mi"
          cpu: "500m"
      ports:
        - containerPort: 80

------------------------------------------------------------------------

ports: Specifies the ports to expose on the container.

containerPort: 80: Exposes port 80 on the container.        

resources: Defines the resource requirements and limits for the container.

requests: Specifies the minimum amount of resources the container needs.

limits: Sets upper limits on the resources the container can consume.

Mibs
Millicourse

-------------------------------------------------------------------------------------------------------------------

nginxsvc.yml

apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    name: myapp
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30000
  type: LoadBalancer

--------------------------------------------------
ports: Specifies the ports to open on the Service.

port: 80: Defines that the Service should listen on port 80.

targetPort: 80: Specifies that the traffic should be forwarded to Pods on port 80.

nodePort: 30000: Opens a specific port on all nodes in the cluster, allowing external traffic to reach the Service.

-------------------------------------------------------------------------------------------------------------------

ReplicaSet

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchExpressions:
      - {key: app, operator: In, values: [nginx]}
  template:
    metadata:
      name: nodeapp
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80

-------------------------------------------------------------------------------------------------------------------

Deployment

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: kammana/nodeapp:v1
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 8080

-------------------------------------------------------------------------------------------------------------------

 Rolling Updates

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodeapp
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
  selector:
    matchLabels:
      app: nodeapp
  template:
    metadata:
      labels:
        app: nodeapp
    spec:
      containers:
      - image: kammana/nodeapp:v2
        name: nodeapp
        ports:
        - containerPort: 8080

maxSurge: Represents the maximum number or percentage of Pods that can be created above the desired number of replicas during an update. Here, it is set to 25%.
maxUnavailable: Represents the maximum number or percentage of Pods that can be unavailable (not running) during an update. Here, it is set to 25%.

-------------------------------------------------------------------------------------------------------------------

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodeapp
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
  selector:
    matchLabels:
      app: nodeapp
  template:
    metadata:
      labels:
        app: nodeapp
    spec:
      containers:
      - image: kammana/nodeapp:v2
        name: nodeapp
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: data-volume
          mountPath: /app/data   # Mount the volume to this path
  volumes:
  - name: data-volume
    persistentVolumeClaim:
      claimName: my-pvc   # Name of the PersistentVolumeClaim

-------------------------------------------------------------------------------------------------------------------

Core API Group (v1)
Extended API Group (apps/v1)

v1: Used for core, stable, and essential resources like Pods, Services, ConfigMaps, etc., which are part of Kubernetes' fundamental operations.

apps/v1: Used for more complex, application-related resources like Deployments, StatefulSets, and DaemonSets, which are managed separately to allow for greater flexibility and evolution.

------------------------------------------------------------------------------------------------------------------

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nodeapp
spec:
  replicas: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
  selector:
    matchLabels:
      app: nodeapp
  template:
    metadata:
      labels:
        app: nodeapp
    spec:
      containers:
        - name: nodeapp
          image: nodeapp
          resources:
            limits:
              memory: "256Mi"
              cpu: "500m"
              ports:
                - containerPort: 8080
              volumeMounts:
                - name: data-volume
                  mountPath: /app/data
  volumes:
    - name: data-volume
      persistentVolumeClaim:
        claimName: my-pvc
--------------------------------------------------------------------------------------------------------------

apiVersion: apps/v2
kind: ReplicaSet
metadata:
  name: nginx
spec:
  replicas: 5
  selector:
    matchExpressions:
      - {key: app, opertaor: In, values: [nginx]}
  template:
    metadata:
      name: nginx
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx
          resources:
            requests:
              memory: "128Mi"
              cpu: "250m"
            limits:
              memory: "256Mi"
              cpu: "500m"
          ports:
            - containerPort: 80
------------------------------------------------------------------------------------------------------------------

withcredentials: Bind credentials to variables

Username and password(separated)
Username Varible: user
Password Variable: pwd

sshagent: SSH Agent

sshagent(['docker-ssh']) {
    // some block
}

-o StrictHostKeyChecking=no

sh "" --> Is Very Important to Perform script on remote shell

To Build Docker Image,Push,and RUN we need install docker on jenkins server

sudo yum install docker -y
sudo sytemctl start docker
sudo sytemctl status docker
sudo sytemctl enable docker
sudo usermod -a -G docker jenkins
sudo systemctl restart jenkins

Docker public_ip:8080

8080:5000
hosport containerport

-------------------------------------------------------------------------------

pipeline{
    agent any
    stages{
        stage('Checkout The Code'){
            steps{
                git branch:'master', credentialsId:'git-ManjuKempaiah', url:'https://github.com/ManjuKempaiah/python-app'
            }
        }
        stage('Docker Build'){
            steps{
                sh 'docker build -t manjukempaiah/pyapp:0.0.1 .'
            }
        }
        stage('Docker Hub Push'){
            steps{
               withCredentials([usernamePassword(credentialsId: 'docker-hub', passwordVariable: 'pwd', usernameVariable: 'user')]) {
             sh "docker login -u ${user} -p ${pwd}"
             sh "docker push manjukempaiah/pyapp:0.0.1"
             } 
            }
        }
        stage('Dcoker Dev Deploy'){
            steps{
                sshagent(['docker-ssh']) {
              sh "ssh -o StrictHostKeyChecking=no ec2-user@172.31.34.174 docker rm -f pyapp"
              sh "ssh ec2-user@172.31.34.174 docker run -d -p 8080:5000 --name pyapp manjukempaiah/pyapp:0.0.1"
             }
            }
        }
    }
}

-----------------------------------------------------------------------

pipeline{
    agent any
    environment{
        DOCKER_TAG = "0.0.2"
    }
    stages{
        stage('Checkout The Code'){
            steps{
                git branch:'master', credentialsId:'git-ManjuKempaiah', url:'https://github.com/ManjuKempaiah/python-app'
            }
        }
        stage('Docker Build'){
            steps{
                sh 'docker build -t manjukempaiah/pyapp:${DOCKER_TAG} .'
            }
        }
        stage('Docker Hub Push'){
            steps{
               withCredentials([usernamePassword(credentialsId: 'docker-hub', passwordVariable: 'pwd', usernameVariable: 'user')]) {
             sh "docker login -u ${user} -p ${pwd}"
             sh "docker push manjukempaiah/pyapp:${DOCKER_TAG}"
             } 
            }
        }
        stage('Dcoker Dev Deploy'){
            steps{
                sshagent(['docker-ssh']) {
              sh "ssh -o StrictHostKeyChecking=no ec2-user@172.31.34.174 docker rm -f pyapp"
              sh "ssh ec2-user@172.31.34.174 docker run -d -p 8080:5000 --name pyapp manjukempaiah/pyapp:${DOCKER_TAG}"
             }
            }
        }
    }
}



----------------------------------------------------------------------

How to manage multi-cluster deployments?

Using KubeFed(Kubernetes Federation) or tools like ArgoCD

---------------------------------------------------------------------

what is CRD (Custom Resource Definition)?

CRDs allow users to define and manage own resources in kubernetes.

---------------------------------------------------------------------
How do you monitor a kubernetes cluster?

Use Grafana and Promotheous for metrics
Use Elasticsearch, Kibana for logging 

---------------------------------------------------------------------

what is the difference between Helm and Kustomize?

Helm: Uses templates for package management
Kustomize: Uses overlays for customization without templates

---------------------------------------------------------------------

How do you mangae statefull applications in Kubernetes?

By using StatefulSets, Persistent Volumes and Persistent Volume Claims.

---------------------------------------------------------------------

How do you handle pod failures?

Use Readiness and Liveness Probes
Set Restart Policies (Always,OnFailure,Never)
Check Node Availability
Check taint and tolerations

---------------------------------------------------------------------

How do you trouble shoot high cpu or memory usage in Kubernetes?

Use kubectl top pods to check resource usage, Check logs with kubectl logs pod_name

---------------------------------------------------------------------

Helm is a package manager for Kubernetes,It simplifies the 
deployment and management of applications in Kubernetes clusters 
by using Helm charts.

---------------------------------------------------------------------

How would you control pod-to-pod traffic for enhanced security?

By uisng Network Policies

---------------------------------------------------------------------

How would a recover a Kubernetes cluster if etcd goes down?

Recovery from etcd Backup (Best Practice)

Step 1: Stop kube-apiserver                (sudo systemctl stop kubelet)
Step 2: Restore etcd from Backup
Step 3: Ensure correct ownership/permissions
Step 4: Restart etcd and kube-apiserver    (sudo systemctl start kubelet)

---------------------------------------------------------------------

how would drain node from maintenance without affecting availability?

Step 1: Check Node and Pod Distribution
Step 2: Cordon the Node
Step 3: Drain the Node
Step 4: Verify Pods are Rescheduled
Step 5: Perform Maintenance on the Node
Step 6: UnCordon the Node

---------------------------------------------------------------------

How do you manage application secrets securely in kubernetes?

Use Kubernetes Secrets to store sensitive data.

Mount secrets into pods as environment variables or files.

Restrict access to secrets using RBAC (permissions).

Enable encryption at rest for secrets in etcd.

use external secret managers like AWS Secrets Manager

---------------------------------------------------------------------

A service is not discoverable inside the cluster - where would you start investigation?

1. Check if the Service Exists
2. Check Pod Labels Match Service Selector
3. Check if Endpoints Are Created
4. Check Pod Status
5. Check Network Policies

kubectl get svc -n <namespace>
kubectl get pods --show-labels -n <namespace>
kubectl describe svc <service-name> -n <namespace>
kubectl get endpoints <service-name> -n <namespace>
kubectl get pods -n <namespace>

---------------------------------------------------------------------

Here are the main types of Kubernetes API objects/resources:

1. Workload Resources (Define what runs in your cluster)

Pod: The smallest deployable unit in Kubernetes. Represents one or more containers.

ReplicaSet: Ensures a specified number of pod replicas are running.

Deployment: Manages ReplicaSets and provides declarative updates to pods.

StatefulSet: Like a Deployment but for stateful applications (e.g., databases).

DaemonSet: Ensures a pod runs on all (or some) nodes.

Job: Runs a task to completion (once or specified times).

CronJob: Runs jobs on a schedule (like cron).

2. Service Resources (Expose and access workloads)

Service: Exposes a set of pods as a network service.

ClusterIP, NodePort, LoadBalancer, ExternalName

Ingress: Manages external HTTP/S access to services.

3. Configuration Resources

ConfigMap: Stores configuration data as key-value pairs.

Secret: Stores sensitive data like passwords or API keys.

4. Storage Resources

PersistentVolume (PV): A piece of storage in the cluster.

PersistentVolumeClaim (PVC): A request for storage by a user.

5. Namespace and Access Control

Namespace: Virtual cluster within a physical cluster to organize resources.

ServiceAccount, Role, RoleBinding, ClusterRole, ClusterRoleBinding: For access control (RBAC).

6. Networking and Policy

NetworkPolicy: Controls traffic flow between pods.

Endpoint: Links Services to Pods.

7. Custom Resources

CustomResourceDefinition (CRD): Allows you to define your own resource types.

---------------------------------------------------------------------

                         DOCKER

---------------------------------------------------------------------

How do you reduce the size of the Docker Image?
                  or
What strategy would you use to shrink docker image?

1.Use official base image
2.choose minimal base image
3.Leverage muli-stage build
4.Minimize image layers
5.Remove unnecessary files and dependencies
6.Use .dockerignore to exclude unwanted files
6.Use distroless images

----------------------------------------------------------------------

How do you limit container resources in docker?

CPU Limit   : docker run --cpus="2" <image_name>  (2 cpu cores)
Memory Limit: docker run --memory="512m" <image_name>  (512 MB)

----------------------------------------------------------------------

How do you check the resource usage of a running container?

docker stats <container_id>

----------------------------------------------------------------------

what happens when you run docker stop vs. docker kill?

docker stop: Garcefully stops the continer.
docker kill: Immediately stops the container without cleanup.

----------------------------------------------------------------------

Docker volumes are persistent storage mechanisms used to store and share
data between containers or between host machine and containers,
independent of the container's lifecycle.

Docker Volumes Types:

1.Volumes
2.Bind Mounts
3.tmpfs Mounts

--------------------------------------------------------------------

Docker Networking

Docker networking enables communication between containers, 
and between containers and the outside world.

--------------------------------------------------------------------
Docker Networking Types:

1.Bridge Network
2.Custom Network
3.Host Network
4.None Network
5.Overlay Network
6.Macvlan Network

--------------------------------------------------------------------
3.Docker Compose

Docker Compose is a tool that defines and manages 
multi-container Docker applications using a YAML file.

docke-compose up -d
docker-compose ps

--------------------------------------------------------------------

docker stop container_id  --- Gracefully stpos the container
docker rm container_id    --- Removes the stopped container
docker kill container_id  --- Immediately stops the container without cleanup
docker top container_id   --- To Diplay the running processes inside the container
docker stats container_id --- To Check resource usage of running container

--------------------------------------------------------------------

How would you update running container without downtime?

By using Rolling Updates
     or
By using Blue-Green Deployments

--------------------------------------------------------------------

How do you handle container networking across different hosts?
                  or
How would you allow two container's to communicate across different docker hosts?

By using Overlay Network 

--------------------------------------------------------------------

How to isolate networking between two containers?

By using custom bridge network or own bridge network

--------------------------------------------------------------------

How can you monitor container health?

1. Docker Health Checks
2. Docker Events and Logs
3. Readiness and Liveness Probes

--------------------------------------------------------------------

You accidentally delete a running container - how do you recover any important data?

By using Docker Volumes 

docker commit <container-id> recovered-image

If you’ve made changes inside a running container 
(e.g., installed packages, changed configs), and you don’t want to 
lose that work, docker commit saves that container as a reusable image.

--------------------------------------------------------------------

How would you configure a persistent storage for a Docker Container?

By using Docker Volumes

--------------------------------------------------------------------

How do you handle versioning of Docker images for different environments? 

1. Use Semantic Versioning (SemVer)
2. Add Environment-Specific Tags

--------------------------------------------------------------------

If a containerized app fails in production, how would you trouble shoot it?

1. Check Container Status
   
   docker ps -a

   Or in Kubernetes: 

   kubectl get pods
   kubectl describe pod <pod-name>

2. Inspect Logs

  docker logs <container_id>

  kubectl logs <pod-name>

3. Check Events

  kubectl get events 

4. Check Resource Usage
   
   docker stats container_id
   kubectl top pod <pod-name>

5. Run Container Interactively
   
   docker exec -it <container_id> bash
   kubectl exec -it <pod-name> -- /bin/bash

6. Check Application Health

7. Look at Monitoring & Alerting Tools

--------------------------------------------------------------------


How do you securely pass environment variables to a container?

 1. Use -e or --env-file (for basic usage)
 2. Use Docker Secrets
 3. Use Kubernetes Secrets (if using K8s)
 4. Use a Secret Manager

 --------------------------------------------------------------------

Features of Docker

1.Consistency: Ensures Applications run the same the way in development,
               testing and production environments

2.Isolation: Containers are isolted from each other and the host system

3.Poratbility: Containers can run on any system that supports docker

4.Scalability: Easy to scale applications horizontally by running multiple
               containers

5.Version Control: Docker Images can be versioned

--------------------------------------------------------------------

Who do you manage secrets inside docker container?

1.Environment Variables
   
   Set secrets as environment variables using -e or --env-file.

   docker run -e DB_PASSWORD=mysecret123 myapp


2.Docker Secrets (for Swarm mode)

3.Use Secret Management Tools

--------------------------------------------------------------------

A container keeps restarting - how would you bedbug it?
                     or
A Docker container keeps existing immediately after starting - how would you trouble shoot it?

 1. Check Container Logs
 2. Check Restart Policy
 3. Check Container Exit Code
 4. Run the Container Interactively
 5. Look at Dockerfile Entrypoint / CMD

--------------------------------------------------------------------

How would you optimize container startup times?

1.Use official base image
2.choose minimal base image
3.Reduce Image Size
4.Avoid Heavy Startup Scripts
5.Minimize Dependencies

--------------------------------------------------------------------





